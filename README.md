## Orchestrating Data Movement with Azure Data Factory

Azure Data Factory (ADF) is the cloud based ETL and data integration service that allows you to create driven workflows for orchestrating data movement and transforming data at scale. 

You can create and schedule data driven workflows called pipelines. It has the following components: Pipeline, Activity, Linked Services, and Datasets. To connect to external resources Data Factory uses Linked Service.

ADF has more than 80 native connectors and is good for data ingestion in batch. Is not suitable for real-time data ingestion.

In this project, I was focused on four learning objectives:

- Set up Azure Data Factory;
- Create a storage account using the Azure portal;
- Create an Azure Data Factory pipeline with Copy Activity;
- Create and set up data flow activity;
- Use a data flow activity to transform the data;


